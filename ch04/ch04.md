# Ch04 机器学习基础

机器学习任务的七步工作流程：
- 模型评估
- 数据预处理
- 特征工程
- 解决过拟合

分类与回归术语表：
- 样本（sample）或者输入（input）：进入模型的数据点
- 预测（prediction）或者输出（output）：从模型出来的结果
- 目标（target）：真实值。理想情况下，对于外部数据源，模型应该能够预测出目标
- 预测误差（Prediction Error）或者 损失值（Loss Value）：模型预测与目标之间的距离
- 类别（class）：分类问题中供选择的一级标签。
- 标签（label）：分类问题中类别标注的具体例子。
- 真值（ground-truth）或者标注（annotation）：数据集的所有目标。
- 二分类（binary classification）：一种分类任务，每个输入样本都应该被划分到两个互斥的类别中
- 多分类（multi-class classification)：一种分类任务，每个输入样本都应该被划分到两个以上互斥的类别中
- 多标签分类（multi-label classification)：一种分类任务，每个输入样本都可以被分配到两个以上的标签
- 标量回归（scalar regression）：目标是连续标量值的任务。
- 向量回归（vector regression）：目标是一组连续值（例如：一个连续向量）的任务
- 小批量（mini-batch）或者批量（batch）：模型同时处理的一小部分样本。样本数通常取2的幂，方便GPU上的内存分配。
训练时，小批量用来为模型权重计算一次梯度下降更新。

## 4.1 机器学习的四个分支

### 4.1.1 监督学习

监督学习：给定一组样本，将输入数据映射到已知目标（也叫标注）
- 序列生成（Sequence Generation）：给定一张图像，预测描述图像的文字。
序列生成也可以表示为一系列分类问题，比如：反复预测序列中的单词或者标记。
- 语法树预测（Sytax Tree Prediction）：给定一个句子，预测其分解生成的语法树
- 目标检测（Object Detection）：给定一张图像，在图中特定目标的周围画一个边界框。
目标检测也可以表示为分类问题（给定多个候选边界框，对每个框内的目标进行分类）
或者分类与回归联合问题（用向量回归来预测边界框的坐标）
- 图像分割（Image Segmentation）：给定一张图像，在特定物体上画一个像素级的掩模（mask）

### 4.1.2 无监督学习

无监督学习：在没有目标的情况下寻找输入数据的变换，是数据分析的必备技能。
目的在于数据可视化、数据压缩、数据去噪或者更好地理解数据中的相关性。
- 数据降维（Dimensionality Reduction）
- 聚类（Clustering）

### 4.1.3 自监督学习

自监督学习是监督学习的特例，是没有人工标注的标签的监督学习，没有人类参与的监督学习。
标签是使用启发式算法从输入数据中生成的。
- 自编码器（autoencoder）：生成的目标是未经修改的输入
- 时序监督学习（Temporally Supervised Learning）：
    - 从给定视频中过去的帧预测下一帧
    - 从给定文本中前面的词预测下一个词

### 4.1.4 强化学习

强化学习：智能体（agent）接收有关其环境的信息，并且学会选择行动，从而得到某种奖励最大化。

## 4.2 评估机器学习模型

机器学习的目的是得到可以泛化（generalize）的模型，即在前所未见的数据上表现很好的模型。

### 4.2.1 训练集、验证集和测试集

评估模型的重点是将数据划分为三个集合：
1. 训练集：在训练数据上训练模型
2. 验证集：在验证数据上评估模型
3. 测试集：在测试数据上测试所找到的模型的最佳参数

信息泄露（information leak）：
- 每次基于模型在验证集上的性能来调节模型超参数，都会有一些关于验证数据的信息泄露到模型中。
因此，如果使用验证数据评估模型的泛化能力是不准确的。
- 使用全部数据进行数据预处理，那么测试集的数据信息就会泄露到训练集的数据中。

将数据划分为训练集、验证集和测试集的三种经典的评估方法：
1. 简单的留出验证（hold-out validation）：
    - 留出一定比例的数据作为测试集用来评估模型，使用剩余的数据训练模型。
    - 缺点：如果可用的数据太少，那么验证集和测试集所包含的样本就太少，从而无法在统计学上代表数据。
2. K 折验证（K-fold validation）：将数据划分为大小相同的 K 个分区。
    - 使用某个分区验证模型，使用剩下的分区训练模型。循环所有的分区验证模型，然后对所有分区的结果求平均
    - 需要独立的测试集对模型进行评估
3. 带有打乱数据的重复 K 折验证（iterated K-fold validation with shuffling）
    - 将数据打乱P次，每次打乱后对数据进行 K 折验证，然后对所有的结果求平均。
    - 缺点：这个方法一共需要训练和评估 P*K个模型，计算代价大。

### 4.2.2 评估模型的注意事项

- 数据代表性（Data Representativeness）：不能使某些数据聚集在某些部分，
会导致分割数据集时某些类别的数据集中在某个数据集中，影响数据的概率分布。
可以使用随机打乱数据来使数据分割结果更加合理。
- 时间箭头（the arrow of time）：如果是序列数据，不可以随机打乱数据，会造成时间泄露。
- 数据冗余（redundancy in your data)：
    - 如果数据中的某些数据点出现了两次以上，那么在分割数据集时一定要确保没有交集；
    - 不能随便删除冗余数据，因为会影响数据的概率分布。

## 4.3 神经网络的数据预处理

### 4.3.1 神经网络的数据预处理
数据预处理的目的是使原始数据更加适合神经网络处理。

数据预处理的常用手段：
- 数据向量化（Data Vectorization）：将数据转换为浮点数张量
- 值标准化：将数据转换为0~1之间的浮点数。
    - 输入数据的标准特征：
        - 取值较小：大部分值的范围应该在0~1范围内
        - 同质性（homogenous）：所有特征的取值都应该在大致相同的范围内。
    - 输入数据的高级特征：
        - 零均值：平均值为0
        - 标准方差：标准差为1
    - 处理缺失值：
        - 将缺失值设为0
        - 将缺失值设为合理的参考值

### 4.3.2 特征工程

特征工程（feature engineering）：将数据输入模型之前，根据学习目标的需要，
利用与数据相关的背景知识和机器学习算法知识对数据进行硬编码的转换，以改善模型的效果。
这种变换不同于模型学到的变换，是由目标驱动的，因此也是机器无法学到的。

特征工程的本质：用更简单的方式表述问题，从而使问题变得更加容易处理。

对于现代深度学习，特征工程的作用：
- 大部分特征工程不再需要
- 良好的特征
    - 可以使用更少的数据
    - 可以使用更少的资源
    - 可以更好的解决问题
    
## 4.4 过拟合与欠拟合 

优化与泛化之间的矛盾：
- 优化（optimization）：调节模型以在训练数据上得到最佳的性能（即机器学习中的学习）
- 泛化（generalization）：训练好的模型在前所未见的数据上得到的性能好坏
- 模型欠拟合：训练开始时，训练数据上的损失越小，测试数据上的损失也越小
- 模型过拟合：训练后期时，训练数据上的损失越小，测试数据上的损失却越大
- 解决方法：
    - 最优方案：获取更多的训练数据，降低训练数据中噪声对模型的影响
    - 次优方案：
        - 减少记忆容量：调节模型允许存储的信息量；
        - 正则化：调节模型允许存储的信息内容

机器学习的目标是得到良好的泛化，但是因为无法控制泛化，所以只能基于训练数据调节模型

### 4.4.1 减小网络大小

模型的容量（capacity）：在深度学习中，模型中可以学习的参数的个数 。

### 4.4.2 添加权重正则化

奥卡姆剃刀（Occam‘s razor）原理：简单的模型比复杂的模型更不容易过拟合。
- 简单模型：参数值分布的熵更小的模型；参数更少的模型

降低过拟合的方法：强制让模型权重只能取较小的值，从而限制模型的复杂度，使得权重值的分布更加规则（regular），
这种方法叫做权重正则化（weight regularization）。

权重正则化的实现方法：向网络损失函数中添加与较大权重值相关的成本。
- L1 正则化：添加的成本与权重系数的绝对值（权重的L1范数）成正比
- L2 正则化：添加的成本与权重系数的平方（权重的L2范数）成正比
    - 神经网络的 L2 正则化也叫做权重衰减（weight decay）。
    
防止神经网络过拟合的常用方法：
- 获取更多的训练数据
- 减小网络容量
- 添加权重正则化
- 添加dropout

## 4.5 机器学习的通用工程流程

### 4.5.1 定义问题，收集数据集

明确输入、输出以及所使用的数据。

### 4.5.2 选择衡量成功的指标

- 对于类别平衡的问题（每个类别的可能性相同），精度和接收者操作曲线下的面积（ROC-AUC）是常用的指标。
- 对于类别不平衡的问题，准确度和召回率是常用的指标。
- 对于排序问题或者多标签问题，平均准确率均值（MAP，Mean Average Precision）是常用的指标。

补充：了解指标与问题之间的关系可以参考Kaggle网站上的数据科学竞赛。

### 4.5.3 确定评估方法

三种经典的评估方法：
- 如果可以使用的样本数据量很大时，可以采用留出验证集
- 如果留出验证的样本量太少，无法保证可靠性，可以采用 K 折交叉验证
- 如果可以使用的样本数据量太少，同时模型评估又需要非常准确，可以采用重复的 K 折交叉验证

### 4.5.4 准备数据
- 数据格式化为张量
- 张量的取值缩放为较小的值
- 数据标准化，从而因为不同的特征具有不同的取值范围导致的异质数据
- 特征工程，解决小数据问题

数据的两个假设：
- 假设输出是可以根据输入进行预测的
- 假设可用的数据包含足够多的信息，满足学习输入和输出之间的关系的需要

### 4.5.5 开发比基准更好的模型

基准模型：一般是随机的基准（dumb baseline）

构建模型的三个关键参数：（参考：表4-1：常用的激活函数和损失函数）
- 最后一层的激活函数：对网络输出进行有效的限制
- 损失函数：匹配需要解决的问题的类型
    - 损失函数需要在只有小批量数据时就可以进行计算
    - 损失函数必须是可微的（否则无法采用反向传播来训练网络）
- 优化器：一般使用 rmsprop 及其默认的学习率

### 4.5.6 扩大模型规模：开发过拟合的模型

开发过拟合的模型，用于确定模型的正确规模：
1. 添加更多的层
2. 添加更多的神经元
3. 训练更多的轮次

### 4.5.7 模型正则化与调节超参数
（这一步最消耗时间和精力，最需要经验和耐心）
- 添加 dropout
- 尝试不同的架构：增加或者减少层数
- 添加 L1 和/或 L2 正则化
- 尝试不同的超参数，找到最佳的配置
- 反复进行特征工程：添加新的特征或者删除没有信息量的特征 