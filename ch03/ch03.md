# Ch03 神经网络入门

## 3.1 神经网络剖析

通过对 **图3-1：网络、层、损失函数和优化器** 的学习，可以将每种机器学习类型采用这个模式分解。
- 层：多个层组合成网络（或者模型）
- 输入数据和相应的目标
- 损失函数，即用于学习的反馈信号
- 优化器，决策学习过程如何进行

### 3.1.1 层：深度学习的基础组件

层是一个数据处理是模块，用于将一个或者多个输入张量转换为一个或者多个输出张量。
- 神经网络的基本数据结构是层。
- 有些层是无状态的，有些层是有状态的，状态即层的权重
- 层的权重利用随机梯度下降学到一个或者多个张量，用于包含网络的知识。

不同的张量格式和不同的数据类型使用不同的层：
- 简单的向量数据保存在形状为2D张量中，使用密集连接层（Dense Connected Layer），也叫密集层，或者叫全连接层
- 序列数据保存在形状为3D张量中，使用循环层（Recurrent Layer），例如：LSTM
- 图像数据保存在形状为4D张量中，使用二维卷积层（Convolutional Layer），例如：Con2D

模型中添加的层都会自动匹配输入层的形状，因此只需要设定第一层的形状，第二层开始的形状将由前一层的形状自动推导

### 3.1.2 模型：层构成的网络

深度学习模型是层构成的有向无环图，描述了网络的拓扑结构，定义了一个假设空间。

常用的网络拓扑结构：
- 层的线性堆叠：将单一输入映射为单一输出
- 双分支（Two-Branch）网络：
- 多头（Multi-head）网络
- Inception 模块

### 3.1.3 损失函数与优化器：配置学习过程的关键

- 损失函数（目标函数）：在训练过程中需要将其最小化
    - 常用的损失函数：
        - 二分类问题：使用二元交叉熵（Binary Cross-entropy）
        - 多分类问题：使用分类交叉熵（Categorical Cross-entropy）
        - 回归问题：使用均方误差（MSE，Mean-Square Error）
        - 序列学习问题：使用联结语义时序分类（CTC，Connectionist Temporal Classification）
- 优化器：在训练过程中决定如何基于损失函数对网络参数进行更新

## 3.2 Keras简介

重要特性：
- 相同的代码可以在CPU和GPU上无缝切换
- 相同的代码可以在多个深度学习的平台上无缝切换（TensorFlow、CNTK、Theano）

### 3.2.2 使用 Keras 开发过程
1. 定义训练数据：输入张量和目标张量
2. 定义层组成的网络（或者模型），将输入映射到目标
    1. 使用 Sequential 类定义模型：仅用于层的线性堆叠
    ```python
        model = models.Sequential()
        model.add(layers.Dense(16, activation = 'relu', input_shape = (100,)))
        model.add(layers.Dense(1, activation = 'sigmoid'))
    ```
    2. 使用函数式 API 定义模型：用于层组成的有向无环图，即任意形式的架构
    ```python
        input_tensor = layers.Input(shape=(100,))
        x = layers.Dense(16,activation = 'relu')(input_tensor)
        output_tensor = layers.Dense(1, activation = 'sigmoid')(x)
        model = models.Model(input = input_tensor, outputs = output_tensor)
    ```
3. 配置学习过程：选择损失函数、优化器和需要监控的目标
4. 调用模型的训练方法fit()在训练数据上迭代学习

## 3.4 二分类问题：电影评论分类

### 3.4.7 小结
- 需要对原始数据进行预处理
- 使用 relu 激活函数进行 密集层堆叠
- 对于二分类问题：
    - 网络的最后一层应该只有一个单元，
    - 使用 sigmoid 激活的 Dense 层
    - 使用 Binary Cross-entropy 损失函数
    - 使用 RMSProp 优化器
    - 网络输出的0~1范围的标题表示概率值。
- 需要监控模型在训练集之外的数据上的性能，防止模型过拟合

## 3.5 多分类问题：新闻分类

- 单标签、多分类问题：每个数据点只允许划分到一个类别，网络的最后一层使用 softmax 激活函数
- 损失函数应该使用分类交叉熵，将网络输出的概率分布与目标的真实分布之间的距离最小化
- 处理多分类问题的标签方法
    - 将标签编码为分类编码（One-Hot 编码），使用 categorical_crossentropy 作为损失函数
    - 将标签编码为整数，使用 sparse_categorical_crossentropy 作为损失函数
- 中间层的神经元个数一定要大于类别数目 N，否则会造成数据传输过程中的信息丢失
- 对 N 个类别的数据点进行分类，网络的最后一层是大小为 N 的 Dense 层
- 多标签、多分类问题：每个数据点可以划分到多个类别

## 3.6 回归问题：预测房价
 
- 回归问题常用的损失函数的损失函数是均方误差（MSE）
- 回归问题常用的评估指标是平均绝对误差（MAE）
- 如果输入数据的特征具有不同的取值范围，应该先进行预处理，对每个特征单独进行缩放
- 如果可以使用的数据太少，可以使用K折验证可以可靠地评估模型
- 如果可以使用的数据太少，可以使用隐藏层比较少（1~2层）的小型网络，以避免严重的过拟合

## 本章小结

- 处理关于向量数据的三种类型问题：
    1. 二分类问题
    2. 多分类问题
    3. 标量回归问题
- 原始数据在输入神经网络处理前需要进行预处理
    - 如果数据特征具有不同的取值范围，那么需要进行预处理，将每个特征单独缩放
- 随着训练次数的增加，神经网络最终会过拟合，并在预测数据上得到更差的评估结果
- 如果训练数据太少
    - 可以减少隐藏层的数量（1~2）层，避免严重的过拟合
    - 可以使用K折验证可以可靠地评估模型
- 如果数据被分为多个类别，那么中间层过小可能会导致信息瓶颈
- 回归问题与分类问题使用的损失函数和评估指标不同