# ch05 深度学习用于计算机视觉

## 5.1 卷积神经网络简介

### 5.1.1 卷积运算

卷积神经网络的性质：
- 卷积神经网络学到的模式具有平移不变性（translation invariant)
- 卷积神经网络可以学到模式的空间层次结构（spatial hierarchies of patterns)

卷积神经网络中的卷积运算从输入特征图中提取图块，并将所有的这些图块应用相同的变换，生成输出特征图。
这个输出特征图仍然是一个3D张量，具有宽度和高度，其深度可以任意取值，因为输出深度是层的参数，
深度轴的不同通道不再像RGB输入那样代表特定颜色，而是代表过滤器（filter）。（参考图5-2）

卷积运算的两个关键参数：
- 从输入中提取的图块尺寸
- 输出特征图的深度：卷积所计算的过滤器的数量

### 5.1.2 最大池化运算

最大池化是从输入特征图中提取窗口，然后输出每个通道的最大值。

最大池化与卷积的区别：
- 最大池化通常使用 2x2的窗口 和 2的步幅；
- 卷积通常使用 3x3的窗口 和 1的步幅

没有池化的架构带来的问题：
- 第三层的3x3窗口中包含的信息是初始输入的7x7窗口中提供的内容，而原始图片是28x28的大小，因此信息量远远不够
需要在最后一个卷积层的特征包含输入的整体信息，才能够为判断提供足够的支持
- 最后一层的特征图对每个样本都有22x22x64个元素，展平后输入到大小为512的Dense层，那么就需要1580万个参数，
模型太大，会造成严重过拟合

使用下采样的原因：
- 减少需要处理的特征图的元素个数 
- 通过让连续卷积层的观察窗口越来越大（即窗口覆盖原始输入的比例越来越大），从而引入空间过滤器的层级结构

下采样的方法：（最大池化最好）
- 最大池化：将每个局部输入图块变换为取该图块各通道的最大值
- 平均池化：将每个局部输入图块变换为取该图块各通道的平均值

特征中往往编码了某种模式或者概念在特征图的不同位置是否存在（因此得名特征图），
而观察不同特征的最大值而不是平均值能够给出更为准确的信息。
因此，最为合理的子采样策略：首先，生成密集的特征图（无步进的卷积）；
然后，观察特征每个小图块上的最大激活，而不是查看输入的稀疏窗口（通过步进卷积）或者对输入图块求平均，
因为后两种方法可能导致错过或者淡化特征是否存在的信息。

## 5.2 在小型数据集上从头开始训练一个卷积神经网络

三种策略：
1. 从头开始训练一个小型模型
    - 5.2.2 下载数据（准备原始训练数据）
    - 5.2.3 构建网络（用于对原始训练数据进行训练）
    - 5.2.4 数据预处理（将原始数据转换成神经网络可以处理的数据）
    - 5.2.5 使用数据增强（对原始数据进行优化——生成模拟样本）
        - 对数据进行随机变换来生成模拟样本
        - 使用 Dropout 方法
2. 使用预训练的网络做特征提取
3. 对预训练的网络进行微调

### 5.2.1 深度学习与小数据问题的相关性

深度学习模型本质上具有高度的可复用性，在大规模数据集上训练的模型可以经过修改就复用于完全不同的问题。

数据量的大小与模型大小相关，如果模型不大，做好正则化，也可以利用卷积神经网络训练得到比较好的结果。

### 5.2.2 下载数据

- 国内链接：https://pan.baidu.com/s/13hw4LK8ihR6-6-8mpjLKDA 密码：dmp4
- 国外链接：需要在 Kaggle 上注册后，还需要请外国朋友帮助下载

### 5.2.3 构建网络

处理更大的图像和更加复杂的问题，需要增大网络容易，减小特征图的尺寸。
注意：P107 维度如何随着每层变化

### 5.2.4 数据预处理

利用 Python 生成器（避免一次处理所有图像带来的内存占用） 将所有图像乘以 1/255 进行缩放。

### 5.2.5 数据增强

解决数据过拟合的办法：
- 数据补充（生成模拟样本）
- 正则化
- dropout

## 5.3 使用预训练的卷积神经网络

预训练网络（Pretained Network）：在大型数据集上训练得到的网络参数的永久保存。

预训练网络的模型：VGG、ResNet、Inception、Inception-ResNet、Xception等等。

使用预训练网络的两种方法：
- 特征提取（Feature Extraction）：
- 微调模型（Fine-Tunning）

### 5.3.1 特征提取

特征提取：使用之前网络学到的表示来从新样本中提取预见有趣的特征，然后将这些特征作为输入在一个新的分类器中训练。
具体参考：图5-14 保持卷积基不变，改变分类器。
因为卷积基学到的表示可能适合复用，因为物体位置信息由卷积特征图描述。
而分类器学到的表示是针对于模型训练的类别，其中仅包含某个类别出现在整张图像中的概率信息。
密集连接层的表示不再包含物体在输入图像中的位置信息，即舍弃了空间的概念。
如果物体位置信息对于问题非常重要，那么密集连接层的特征在很大程度上是无用的。

某个卷积层提取的表示的的通用性及复用性取决于这个层在模型中的深度。
- 模型中靠近底部的层提取的是局部的、高度通用的特征图（例如：视觉边缘、颜色、纹理等）
- 模型中靠近顶部的层提取的是抽象的概念（例如：猫耳朵、狗眼睛等）

因此需要根据新数据集和原始数据集的差异很大，那么只好只使用模型的前几层来做特征提取，而不是使用整个卷积基。

具体步骤：
1. 载入预训练模型
2. 添加一个密集连接分类器
    - 在自己的数据集上运行卷积基，将输出保存成硬盘中的 Numpy 数组，
    然后用这个数据作为输入，输入到独立的密集连接分类器中。
    这种方法速度快，计算代价低，对每个输入图像只需要运行一次卷积基（卷积基是整个流程中计算代价最高的）。
    但是这种方法无法使用数据增强（可以自己先手工补充数据，当然就无法使用别人已经提供好的开发框架）
    - 在顶部添加 Dense 层来扩展模型（即导入的预处理模型），并在输入数据上端到端的运行整个模型。
    这样就可以使用数据增强，也能保证每个输入图像进入模型时都会经过卷积基。
    但是缺点就是计算代价要高很多。
        - 在编译和训练模型之前，一定要“冻结”卷积基。
        - 冻结（freeze）：一个或者多个网络层是指在训练过程中保持其权重不变。
        如果不在学习之前冻结卷积基，那么前面学到的表示会在训练过程中被修改，从而会给之前学到的表示造成很大的破坏。

### 5.3.2 微调模型

模型复用方法——模型微调（Fine-Tuning）：与特征提取互为补充。
对于用于特征提取的冻结的模型基，微调是指对其顶部的几层“解冻”，并将解冻的这几层和新增强的部分联合训练。
因为训练只是略微调整了所复用模型中更加抽象的表示，以便让这些表示与手头的问题更加相关，所以叫“微调”。

微调的步骤：
1. 在已经训练好的基网络上添加自定义网络
2. 冻结基网络
3. 训练所添加的部分
4. 解冻基网络的前面几层
5. 联合训练解冻的这些层和添加的部分

解冻的原则：
- 卷积基中更靠底部的层编码的是更加通用的可利用特征，而更顶部的层编码的是更加专业化的特征。
微调这些专业化的特征更加有效，因为这些特征与需要解决的问题更加相关
- 训练的参数越多，过拟合的风险也越大。

### 5.3.3 小结
- 卷积神经网络是用于计算机视觉任务的最佳机器学习模型。
即使在非常小的数据集上也可以从头开始训练一个卷积神经网络，而且能够得到相对较好的结果。
- 在小型数据集上的主要问题是过拟合。
在处理图像数据时，数据增强是一种降低过拟合的好办法
- 特征提取：可以将现有的卷积神经网络复用到新的数据集上。
对于小型的图像数据集，是个好办法
- 模型微调：可以作为特征提取方法的补充，将现在模型之前学到的一些数据表示应用于新的问题。
对于小型的图像数据集，还可以进一步提高模型的性能。

## 5.4 卷积神经网络的可视化
- 可视化卷积神经网络的中间输出（中间激活）：有助于理解卷积神经网络连续的层如何对输入进行变换，也有助于了解卷积神经网络每个过滤器的含义
- 可视化卷积神经网络的过滤器：有助于理解卷积神经网络中每个过滤器容易接受的视觉模式或者视觉概念
- 可视化图像中类激活的热力图：有助于理解图像的哪个部分被识别为哪个类别，从而有助于定位图像中的物体

### 5.4.1 可视化中间激活
- 第一层是各种边缘探测器的集合。
在这一阶段，激活几乎保留了原始图像中的所有信息
- 随着层数的加深，激活变得越来越抽象，也越来越难以直观地理解。
因为激活开始表示更高层次的概念（例如：猫耳朵、猫眼睛等等）
层数越泞，表示中关于图像视觉内容的信息就越少，关于类别信息的内容就越多。
- 随着层数的加深，激活的稀疏度越来越大。
第一层中，所有过滤器都被输入图像激活；后面的层里，越来越多的过滤器都是空白，即输入图像中找不到这些过滤器所编码的模式。

### 5.4.2 可视化卷积神经网络的过滤器

过滤器可视化包含了卷积神经网络的层是如何观察世界的：
- 卷积神经网络中每一层都学习一组过滤器，以便将其输入表示为过滤器的组合
类似于Fourier变换将信号分解为一组余弦函数的过程
- 模型第一层（block1_conv1）的过滤器对应简单的方向边缘和颜色（还有一些是彩色边缘）
- 模型第二层（block2_conv1）的过滤器对应边缘和颜色组合而成的简单纹理
- 模型更高层的过滤器对应自然图像中的纹理：羽毛、眼睛、树叶等

### 5.4.3 可视化类激活的热力图

可视化方法解决了两个问题：
- 网络模型为什么会判断这张图像中包含了一头非洲象？
- 非洲象在图像中的什么位置？

## 本章小结
- 卷积神经网络是解决视觉分类问题的最佳工具
- 卷积神经网络通过学习模块化模式和概念的层次结构来表示视觉世界
- 卷积神经网络学到的表示很容易可视化，卷积神经网络不是黑盒
- 从头训练卷积神经网络来解决图像分类问题
- 使用视觉数据增强来防止过拟合
- 使用预训练的卷积神经网络进行特征提取与模型微调
- 卷积神经网络的可视化
    - 过滤器可视化
    - 类激活热力图可视化