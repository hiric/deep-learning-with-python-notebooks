# ch08 生成式深度学习

## 8.1 使用 LSTM 生成文本

### 8.1.2 如何生成序列数据

标记（TOKEN）通常是单词或者字符，给定前面的标记，能够对下一个标记的概率地建模的任何网络都叫做语言模型（Language Model）。

语言模型能够捕捉到语言的潜在空间（Laten Space），即语言的统计结构。

训练好语言模型后，就可以从中采样（即生成新的序列）。向模型中输入一个初始文本字符串（即条件数据），
要求模型生成下一个字符或者下一个单词（甚至可以同时生成多个标记），然后将生成的输出添加到输入数据中，
并且多次重复这个过程。这个循环可以生成任意长度的序列，这些序列反映了模型训练数据的我，与人类书写的句子几乎相同。

LSTM叫做字符级的神经语言模型。（图8-1）

### 8.1.3 采样策略的重要性

生成文本时，选择下一个字符的方法：
- 贪婪采样（Greedy Sampling）：始终选择可能性最大的下一个字符。
- 随机采样（Stochastic Sampling）：从下一个字符的概率分布中进行采样。
    - softmax 温度：用于控制采样过程中的随机性，表示采样概率分布的熵，即表示所选择的下一个字符的可预测性

生成序列的熵：
- 更小的熵可以让生成的序列具有更加可以预测的结构
- 更大的熵会得到更加出人意料，并且更加具有创造性的序列。

### 8.1.5 小结
- 生成离散的序列数据：给定前面的标记，训练一个模型来预测后面的标记
- 训练的模型对于文本数据来说就是语言模型
    - 单词级的语言模型
    - 字符级的语言模型
- 对于采样下一个标记，需要平衡模型的判断与随机的选择
    - 随机性可以基于 softmax 温度来调节
    
### 8.2 Deep Dream

Deep Dream 与 ch05的卷积神经网络过滤器可视化技术的区别：
- 使用DeepDream，尝试将所有层的激活最大化，而不是将某一层的激活最大化，因此需要同时将大量特征的可视化混合在一起
- 使用DeepDream，是从现有的图像开始，而不是从空白的、略带噪声的输入开始，因此所产生的效果能够抓住已经存在的视觉模式，
并且以某种艺术性的方式将图像元素扭曲
- 使用DeepDream，输入的图像是在不同的尺度（octave，八度音阶）上进行处理的，这样可以提高可视化的质量。

### 8.2.2 小结
- Deep Dream 是反向运行下一个卷积神经网络，是基于网络学到的表示来生成输入
- 得到的结果有些类似于通过迷幻剂扰乱视觉皮层而诱发的视觉伪影
- 这个过程既可以应用于图像模型，也可以应用于语音模型、音乐模型等等

## 8.3 神经风格迁移（Neural Style Transfer）

神经风格迁移是指将参考图像的风格应用于目标图像，同时保留目标图像的内容。
- 风格（style）：是指图像中不同空间尺度的纹理、颜色和视觉图案
- 内容（content）：是指图像的高级宏观结构
- 神经网络迁移实现的关键：定义下一个描述内容和风格的损失函数
    - 相关函数：
        - distance()是一个范数函数（例如：L2范数）
        - style()是一个函数
        - content()是一个函数
    - 风格损失：distance(style(reference_image)-style(generated_image))
        - Gatys使用层激活的格拉姆矩阵（Gram Matrix），即某一层特征图的内积
            - 内积：表示这层特征之间相互关系的映射，
            这种相互关系描述了在特定空间尺度下模式的统计规律，
            对应于这个尺度上找到的纹理的外观。
        - 风格损失的目的：在风格参考图像与生成图像之间，在不同的激活内保存相似的内部相互关系。
        保证了在风格参考图像与生成图像之间，不同空间尺度找到的纹理看起来都很相似。
        - 风格损失使用预训练的卷积神经网络来定义
            - 在目标内容图像和生成图像之间保持相似的较高层激活，从而能够保留内容。
            - 在目标内容图像和生成图像之间在较低层和较高层的激活中保持类似的相互关系，从而能够保留风格。
            特征相互关系捕捉到的纹理，风格参考图像和生成图像在不同的空间尺度上应该具有相同的纹理。
    - 内容损失：distance(content(original_image)-content(generated_image))
        - 网络靠近底层的激活包含关于图像的局部信息、细节的信息
        - 网络靠近顶层的激活包含关于图像的全局的信息、抽象的信息
        - 内容损失常使用两个激活之间的 L2 范数
            - 一个是预训练的卷积神经网络靠近顶部的某层在目标图像上计算得到的激活
            - 一个是同一层在生成图像上计算得到的激活
### 8.3.4 小结
- 风格迁移：是指创建一张新图像，保留目标图像的内容 和 参考图像的风格
    - 内容：是指可以被卷积神经网络更靠顶部的层激活所捕捉到的信息
    - 风格：是指可以被卷积神经网络不同层激活的内部相互关系所捕捉到的信息
- 在深度学习中风格迁移可以表述为一个最优化过程，使用一个预训练卷积神经网络所定义的损失

## 8.4 用变分自编码器生成图像

图像生成领域中两种主要的实现技术：
- 变分自编码器（VAE，Variational Autoencoder）
- 生成式对抗网络（GAN，Generative Adversarial Network）

### 8.4.1 从图像的潜在空间中采样

图像生成的关键思想：找到一个低维的表示潜在空间（Laten Space，即一个向量空间），其中任意点都可以被映射为一张逼真的图像。
以潜在点作为输入，并且将输入映射为一张图像（像素网络）作为输出，这个模块叫做：
- 生成器（generator，对于 GAN 而言）
- 解码器（decoder，对于 VAE 而言）

### 8.4.2 图像编辑的概念向量

概念向量（Concept Vector）：给定一个表示的潜在空间或者一个嵌入空间，
空间中的特定方向可能表示原始数据中有趣的变化轴。

### 8.4.3 变分自编码器

自编码器是一种网络类型，是一种生成式模型，目的是将输入编码到低维潜在空间，然后再解码回高维空间。
经典的图像自解码器接收一张图像，通过一个编码器模块将其映射到潜在向量空间，
然后再通过一个解码器模块将其解码为与原始图像具有相同尺寸的输出。
使用与输入图像相同的图像作为目标数据来训练这个自编码器，即自编码器学习对原始输入进行重新构建。
自编码器学习对原始输入进行重新构建。通过对输出施加各种限制，从而让自编码器学到比较有趣的数据潜在表示。
最常见的结果是：将代码限制为低维的并且是稀疏的，即编码器的作用是将输入数据压缩为更少二进制位的信息。

VAE 的工作原理：
1. 一个编码器模块将输入样本 imput_img 转换为表示潜在空间中的两个参数 z_mean 和 z_log_variance；
2. 假定潜在正态分布能够生成输入图像，并且从这个分布中随机采样一个点 z: z=z_mean+exp(z_log_variance)*epsilon，
其中 epsilon 是取值很小的随机张量
3. 一个解码器模块将潜在空间的这个点映射回原始输入图像

VAE 的参数通过两个损失函数来进行训练：
- 重构损失（Reconstruction Loss）：迫使解码后的样本匹配初始输入
- 正则化损失（Regularization Loss）：有助于学习具有良好结构的潜在空间，并且可以降低在训练数据上的过拟合。

```python
# 将输入图像编码为平均值和方差两个参数
z_mean, z_log_variance = encoder(input_img)
# 使用小随机数 epsilon 来抽取一个潜在点
z = z_mean + exp(z_log_variance) * epsilon
# 将 z 解码为一张图像
reconstructed_img = decoder(z)
# 将自编码器模型实例化，将一张输入图像映射为它的重构
model = Model(input_img, reconstructed_img)
```
### 8.4.4 小结

- 用深度学习进行图像生成，通过对潜在空间进行学习来实现的
    - 这个潜在空间能够捕捉到关于图像数据集的统计信息。对潜在空间中的点进行采样和解码，可以生成未知的图像。
    - 常用的方法：变分自编码器（VAE）和生成式对抗网络（GAN）
- VAE 得到的潜在空间是高度结构化的、连续的潜在表示。
- GAN 得到的是逼真的单幅图像，但是得到的潜在空间可能没有良好的结构，也没有很好的连续性。

## 8.5 生成式对抗网络简介

生成式对抗网络（GAN，Generative Adversarial Network）：能够迫使生成图像与真实图像在统计上几乎无法区分，从而生成相当逼真的合成图像。

GAN 的组成：
- 生成器网络（Generator Network）：以一个随机向量（潜在空间中的一个随机点）作为输入，并且将其解码为一张合成图像
- 判别器网络（Discriminator Network）或者 对手（Adversary）：以一张图像（真实的或者合成的均可）作为输入，
并且预测该图像是来自训练集还是由生成器网络创建。

### 8.5.1 GAN 的简要实现流程

1. generator 网络将形状为（latent_dim，）的向量映射到形状为（32，32，3）的图像。
2. discriminator 网络将形状为（32，32，3）的图像映射到一个二进制分数，用于评估图像为真的概率
3. gan 网络 generator 网络和 discriminator 网络连接在一起：gan(x)=discriminator(generator(x))
    - 生成器将潜在空间解码为图像
    - 判别器对这些图像的真实性进行评估
    - 对抗网络将这些潜在向量映射到判别器的评估结果
4. 使用带有“真”/“假”标签的真假图像样本来训练判别器，就和训练普通的图像分类模型一样
5. 为了训练生成器，要使用对抗模型的损失相对于生成器权重的梯度。
    - 通过调整生成器的权重，努力生成让判别器划分为“真”的图像
    
### 8.5.2 大量技巧
- 生成器最后一层的激活函数使用 tanh 函数，而不是 sigmoid 函数
- 对潜在空间的点进行采样使用正态分布，而不是均匀分布
- 通过往训练过程中引入随机性可以提高训练对抗网络的稳健性，避免对抗网络因为动态平衡而被“卡住”
    - 引入随机性的方法：在判别器中使用dropout；在判别器的标签添加随机噪声
- 稀疏的梯度会妨碍GAN的训练。
    - 使用步进卷积代替最大池化来进行下采样来避免梯度稀疏
    - 使用LeakyReLU层来代替ReLU激活，因为允许较小的负数激活值，放宽了稀疏性限制，来避免梯度稀疏
- 图像中出现棋盘状伪影是因为生成器中像素空间的不均匀覆盖导致的
    - 在生成器和判别器中使用步进的Conv2DTranspose或者Conv2D时，内核大小要能够被步幅整除
    
### 8.5.6 如何训练 DCGAN
1. 从潜在空间中抽取随机的点（随机噪声）
2. 利用这个随机噪声用生成器生成图像
3. 将生成图像与真实图像混合
4. 使用这些混合后的图像以及相应的标签来训练判别器
5. 在潜在空间中随机抽取新的点
6. 使用这些随机向量以及全部是“真实图像”的标签来训练对抗网络

### 8.5.7 小结
- GAN 是由一个生成器网络和一个判别器网络组成
    - 判别器的训练目标是能够区分生成器的输出与来自训练集的真实图像
    - 生成器的训练目标是能够生成判别器无法检测真实性的图像
        - 生成器没有真实图像作为训练集
        - 生成器得到的信息都来自于判别器
- GAN 的训练是一个动态过程，训练难度很大
    - 为了正确训练 GAN，需要一些启发式的技巧，还需要大量的调节
- GAN 可能会生成非常逼真的图像，但是得到的潜在空间没有整齐的连续结构，无法适用于某些实际的应用

## 本章总结
- 序列数据的生成：每次生成一个时间步，应用于文本生成、音乐生成或者其他任何类型的时间序列数据
- Deep Dream 的工作原理：通过输入空间中的梯度上升卷积神经网络的层激活最大化
- 风格迁移：可以将内容图像和风格图像组合在一起，保留内容图像的内容（结构）和风格图像的风格（纹理）
- 对抗式生成网络 和 变分自编码器 都是利用潜在空间概念向量进行图像编辑，都可以用于创造新的图像